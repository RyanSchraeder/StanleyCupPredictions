{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "# Models\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb \n",
    "\n",
    "## Pre-Processing\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score #train/test split & k-fold cross validation\n",
    "from sklearn.preprocessing import StandardScaler #scaler\n",
    "from sklearn.decomposition import PCA #principle component analysis\n",
    "\n",
    "## Scoring \n",
    "import scipy.stats as stats\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db593789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game Outcome Predictors \n",
    "\n",
    "x = classification_df.loc[:, classification_df.columns != 'outcome']\n",
    "y = classification_df['outcome']\n",
    "\n",
    "# Creating the Train and Test Split\n",
    "\n",
    "# Use a train and test split for initial training & testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Length of Values\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"x_train count\": len(x_train),\n",
    "    \"x_test count\":len(x_test),\n",
    "    \"y_train count\":len(y_train), \n",
    "    \"y_test count\":len(y_test)\n",
    "},index=[0]).melt()\n",
    "\n",
    "# Building, Training, and Testing the Model Stack\n",
    "## Building each model with some fun inheritance! \n",
    "\n",
    "class model_development: \n",
    "    \n",
    "    def __init__(self, model, predictors, target): \n",
    "        self.model = model\n",
    "        self.predictors = predictors\n",
    "        self.target = target \n",
    "\n",
    "    def ensemble(names: List[str], models: List) -> Dict[str, Any]: \n",
    "        \"\"\" Creates a dictionary with each model name and the model associated \"\"\"\n",
    "        models = {names[i]: models[i] for i in range(len(names))}\n",
    "        return models\n",
    "\n",
    "    def evaluate(models, x_train, y_train, x_test) -> Dict[str, Any]:\n",
    "        \"\"\" \n",
    "        1) Conducts PCA for feature selection and k-fold cross-validation on each model \n",
    "        2) Evaluates each model with accuracy, precision, and recall scores and returns all average scores \n",
    "        \"\"\"\n",
    "\n",
    "        pca = PCA(n_components=10)\n",
    "        pca.fit_transform(x_train, y_train)\n",
    "        \n",
    "        cv = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "            \n",
    "        scores = {\n",
    "            names: \n",
    "                {\n",
    "                    'Accuracy': cross_val_score(models, x_train, y_train, scoring='accuracy', cv=cv).mean(), \n",
    "                    'Precision': cross_val_score(models, x_train, y_train, scoring='precision', cv=cv).mean(), \n",
    "                    'Recall': cross_val_score(models, x_train, y_train, scoring='recall', cv=cv).mean()   \n",
    "                }\n",
    "             for (names, models) in models.items()\n",
    "        }\n",
    "\n",
    "        return scores\n",
    "    \n",
    "    def predict(model, x_test): \n",
    "        predictions = model.predict(x_test)\n",
    "        return predictions\n",
    "\n",
    "## Pass in the models we wish to stack \n",
    "\n",
    "models = model_development.ensemble(\n",
    "    names =  ['logit', 'svm'],\n",
    "    models =  [\n",
    "        LogisticRegression(),\n",
    "        SVC(kernel='rbf', gamma=0.05),\n",
    "    ]\n",
    ")\n",
    "\n",
    "models\n",
    "\n",
    "## Process, Train, Evaluate\n",
    "\n",
    "summary = model_development.evaluate(models, x_train, y_train, x_test)\n",
    "summary = pd.DataFrame.from_records(summary)\n",
    "summary\n",
    "\n",
    "# Training and Implementing the Stacking Model\n",
    "# Train and implement stacking model \n",
    "\n",
    "def stacking_model(x_train, y_train, x_test, n_folds):\n",
    "    \n",
    "    global cv \n",
    "    cv = KFold(n_splits= n_folds, random_state=0, shuffle=True)\n",
    "    \n",
    "    gbm = xgb.XGBClassifier(\n",
    "        n_estimators= 2000,\n",
    "        max_depth= 4,\n",
    "        min_child_weight= 2,\n",
    "        gamma=0.9,                        \n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "    scale_pos_weight=1).fit(x_train, y_train)\n",
    "    \n",
    "    return gbm\n",
    "\n",
    "def scores():\n",
    "    \n",
    "    scores = [\n",
    "        cross_val_score(xgb, x_train, y_train, scoring='accuracy', cv=cv).mean(), \n",
    "        cross_val_score(xgb, x_train, y_train, scoring='precision', cv=cv).mean(), \n",
    "        cross_val_score(xgb, x_train, y_train, scoring='recall', cv=cv).mean()   \n",
    "    ]\n",
    "\n",
    "    return scores \n",
    "\n",
    "xgb = stacking_model(x_train, y_train, x_test, 10)\n",
    "\n",
    "\n",
    "summary['stacked_model'] = scores()\n",
    "summary\n",
    "\n",
    "The XGBoost Classifier boasts a high accuracy score upon the data, however to prevent overfitting we use this to stack our other algorithms for a final output:\n",
    "clf_stack = StackingClassifier(classifiers = models, meta_classifier = lr, use_probas = True, use_features_in_secondary = True)\n",
    "\n",
    "# Generating Predictions from the Stacked Model\n",
    "# Generate Predictions. Predictions will favor the away team (1: Win, 0: Loss)\n",
    "\n",
    "games['predictions'] = model_development.predict(xgb, x)\n",
    "\n",
    "\n",
    "pd.DataFrame({\n",
    "    'Predicted': games.predictions.value_counts(),\n",
    "    'Actual': games.outcome.value_counts()\n",
    "})\n",
    "\n",
    "conf_matrix = confusion_matrix(games['outcome'], games['predictions'])\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "group_names = ['True Pos', 'False Pos', 'False Neg', 'True Neg']\n",
    "\n",
    "counts = [\"{0:0.0f}\".format(value) for value in conf_matrix.flatten()]\n",
    "percentage = [\"{0:.2%}\".format(value) for value in conf_matrix.flatten()/np.sum(conf_matrix)]\n",
    "\n",
    "labels = [f\"{i}\\n{j}\\n{k}\" for i, j, k in zip(group_names, counts, percentage)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "ax = sns.heatmap(conf_matrix, annot=labels, cmap='Greens', fmt='')\n",
    "ax.set_title('Confusion Matrix for Predicted Outputs')\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.xaxis.set_ticklabels(['Home', 'Away'])\n",
    "ax.yaxis.set_ticklabels(['Home', 'Away'])\n",
    "\n",
    "# Assessing Output Predictions\n",
    "\n",
    "Per the classification of the categorical game outcome, predictions are: \n",
    "- _*Home Win*_ : 0\n",
    "- _*Away Win*_ : 1\n",
    "\n",
    "The confusion matrix will show the: \n",
    "- True Positives\n",
    "- False Positives\n",
    "- True Negatives\n",
    "- False Negatives\n",
    "# Evaluation\n",
    "In summary, the models trained especially well with test data and similar results yield from training them on the original data. The random forest algorithm is overfit with 100% accuracy and appears to have been confused with the binary inputs and classification variables, so some cross-validation and better processing will need to be done. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "plaintext"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
